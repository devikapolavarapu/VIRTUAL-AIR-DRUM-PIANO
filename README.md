# ğŸµ Virtual Air Drum & Piano

A **real-time gesture-controlled virtual musical instrument** that allows users to play **drums and piano in mid-air** using only a webcam.  
The project uses **computer vision and hand-gesture recognition** to detect fingertip movements and trigger corresponding sounds with low latency.

This system demonstrates how **Humanâ€“Computer Interaction (HCI)** can be built using **vision-based input** instead of physical hardware.

---

## 1ï¸âƒ£ ğŸš€ Project Overview

**Virtual Air Drum & Piano** tracks hand landmarks in real time using **MediaPipe**, processes fingertip motion using **OpenCV**, and triggers instrument sounds using **pygame**.

The same gesture-detection pipeline supports **two instrument modes**:

- ğŸ¥ **Drum Mode** â€“ Percussion-based virtual drum pads  
- ğŸ¹ **Piano Mode** â€“ Musical note-based virtual piano keys  

The project is **modular, scalable, and designed with extensibility in mind**.

---

## 2ï¸âƒ£ âœ¨ Key Features

- ğŸ¥ Live webcam-based hand tracking  
- âœ‹ Fingertip detection using MediaPipe (21 landmarks)  
- âš¡ Velocity-based downward tap detection (noise-resistant)  
- ğŸ§­ Spatial zone mapping for gesture interpretation  
- ğŸ”Š Low-latency real-time audio playback  
- ğŸ¹ Dual instrument support (Drum & Piano modes)  
- ğŸ§  Clean cooldown & debouncing logic  
- âŒ¨ï¸ Press **`q`** to exit safely  

---

## 3ï¸âƒ£ ğŸ¥ Drum Mode

**Drum Mode** maps the screen into **five vertical percussion zones**.

### ğŸ§­ Zone Mapping

| Zone | Instrument |
|----|-----------|
| 1 | Kick |
| 2 | Snare |
| 3 | Hi-Hat |
| 4 | Tom |
| 5 | Clap |

### ğŸ” How It Works
1. A fast downward fingertip tap is detected  
2. The **X-axis position** determines the drum zone  
3. The corresponding **drum sound** is triggered  

### â–¶ï¸ Run Drum Mode
```
python main.py
```

4ï¸âƒ£ ğŸ¹ Piano Mode

Piano Mode extends the same gesture pipeline to a melodic instrument.

The screen is divided into seven virtual piano keys:

C   D   E   F   G   A   B


Each key corresponds to a musical note frequency.
A fingertip tap on a key triggers the respective piano note.

This mode demonstrates project extensibility without rewriting core logic.

â–¶ï¸ Run Piano Mode
``` python piano_mode.py ```

5ï¸âƒ£ ğŸ› ï¸ Tech Stack
Category	Technologies
Programming Language	Python 3.10+
Computer Vision	OpenCV
Hand Tracking	MediaPipe
Audio Engine	pygame
Numerical Computing	NumPy
Version Control	Git & GitHub
6ï¸âƒ£ â–¶ï¸ How to Run the Project
ğŸ”¹ Prerequisites

Python 3.10 or higher

Functional webcam

Windows / macOS / Linux

ğŸ”¹ Install Dependencies
```pip install opencv-python mediapipe pygame numpy```

ğŸ”¹ Run Drum Mode
```python main.py```

ğŸ”¹ Run Piano Mode
```python piano_mode.py```

7ï¸âƒ£ ğŸ® How to Use

Place your hand in front of the webcam

Use your index finger

Perform a fast downward tap

Move left â†” right to select instruments or notes

Press `q` to exit

8ï¸âƒ£ ğŸ‘©â€ğŸ’» Author

Devika Polavarapu, 
 B.Tech â€“ Information Technology

Interests:

Computer Vision

AI & Humanâ€“Computer Interaction

Real-world software systems

ğŸ”— GitHub: https://github.com/devikapolavarapu
